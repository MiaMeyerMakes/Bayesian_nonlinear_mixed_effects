---
title: "Literature review Puromycin study"
author: "M Meyer (22675760)"
date: "2024-12-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(nimble)
library(ggplot2)
library(coda)
library(MCMCvis)
library(wesanderson)
library(nlme)
library(knitr)
library(rstan)
library(tidyverse)
```

# Example 1: Puromycin dataset

*The `Puromycin` data frame has 23 rows and 3 columns of the **reaction velocity** versus **substrate concentration** in an enzymatic reaction involving untreated cells or cells treated with Puromycin.*

Load in the data:

```{r}
library("datasets")
puro <- datasets::Puromycin
puro$nstate <- abs(as.numeric(puro$state)-2) #1-0 treatment indicator
```

Visual exploration:

```{r}
ggplot(Puromycin, aes(x = conc, y = rate, color = state)) +
  geom_point(size = 2) +
  labs(
    title = "Rate vs Concentration by Treatment State",
    x = "Concentration",
    y = "Rate",
    color = "Treatment State"
  ) +
 # geom_smooth(size=1)+
  theme_minimal()
```

## Frequentist approach

**Michaelis-Menten kinetic model**. Note that starting values are given in the documentation for the `Puromycin` dataset in the `datasets` package.

The model is: $$
f(\textbf{x}, \boldsymbol{\theta})=\frac{(\theta_1+\theta_3.x_2)\times x_1}{\theta_2 + x_1}+\epsilon
$$ where $\epsilon\sim N(0, \sigma^2)$.

Here $f$ is the response variable and represents the reaction rate, $\theta_1$ represents the maximum reaction rate and $\theta_2$ is the *Michaelis constant*, which is the substrate concentration at which the reaction rate is half of $\theta_1$. Lastly, we have added the conditioning on the state variable to the traditional model and therefore $\theta_3$ is included as the difference in rate for the trajectories of the two classes, with $x_2$ serving as an indicator function for treated subjects. [Here](https://www.datacamp.com/tutorial/introduction-to-non-linear-model-and-insights-using-r) is a link to the source of the model explanation and code.

From the model below, the estimates indicate that the untreated group has a maximum reaction rate of 166.60, the treatment increases the maximum reaction rate by 42.03 to a rate of 208.63. Lastly, the Michaelis constant is estimated as $\hat{K}=0.05797$ and reflects the subtrate affinity.

The model provides a good fit, as is indicated by the low residual standard error of 10.59 and the high statistical significance of all three parameters.

```{r, fig.asp=1}
require(stats); require(graphics)

# options(show.nls.convergence=FALSE)

fm0 <- nls(rate ~ (Vmax + incr*(state=="treated"))*conc/(K+conc), Puromycin,
               list(Vmax=160, incr=40, K=0.05))

summary(fm0)
(fm0$convInfo)$finIter

mm_fit <- predict(fm0, newdata= Puromycin)
puro$mod_est <- mm_fit

# Plot using ggplot2
ggplot(puro, aes(x = conc, y = rate, color = state, shape = state)) +
  geom_point(size = 2) +
  geom_line(data = puro, aes(x = conc, y = mod_est, color = state), linewidth = 0.8) +
  labs(
    title = "Puromycin Data and Fitted Michaelis-Menten Curves",
    x = "Substrate concentration (ppm)",
    y = "Reaction velocity (counts/min/min)",
    color = "Treatment State",
    shape = "Treatment State"
  ) +
  theme_minimal()
```

Next we can evaluate the assumption of normally distributed residuals.

```{r, fig.asp=1}
# Extract residuals
residuals <- residuals(fm0)
var(residuals)
# Create QQ plot
qqnorm(residuals, main = NULL)
qqline(residuals, col = "red", lwd = 2)
```

## Bayesian approach

### Theory recap (for myself)

Remember that we want to use a non-informative prior when we want to incorporate as little as possible prior information into the analysis and allow the data to 'speak for itself'. This is often the case when we don't have enough prior knowledge or when we want the analysis to be as objective as possible.

The **Jeffreys' prior** is a type of *non-informative prior* used in Bayesian statistics. It is designed to be invariant under reparameterisation, meaning the results of Bayesian inference remain the same regardless of how the parameter of interest is expressed (e.g., in different scales). This property makes the Jeffreys' prior particularly useful in situations where there is no natural or obvious choice for a prior distribution.

The Jeffreys' prior is proportional to the square root of the determinant of the Fisher information matrix: $$
\pi(\theta) ∝\sqrt{det\left(I(\theta)\right)} $$

The *classical* Jeffreys' prior refers to the application of Jeffreys' method for constructing a non-informative prior for a **single parameter**. It is often used as the standard or canonical prior in Bayesian statistics when no prior information is available. This prior is proportional to the square root of the Fisher information for the parameter of interest. $$
\pi(\theta) ∝\sqrt{I\left(\theta\right)} $$

Remember that the Fisher information matrix is: $$
I(\theta)=-E\left[\frac{\partial^2 \log L(\theta)}{\partial\theta^2}\right]$$

First we define the model in `nimble`:

```{r}
conc <- Puromycin$conc
y <- Puromycin$rate
state <- state_numeric <- ifelse(Puromycin$state == "treated", 1, 0)

# Define the model in nimble
# code <- nimbleCode({
#   for (i in 1:N) {
#     y[i] ~ dnorm(mu[i], tau)  # Likelihood
#     mu[i] <- ((Vm + delV * I(state[i] == "treated")) * conc[i]) / (K + conc[i])  # Michaelis-Menten equation with treatment effect
#   }
#   
#   # Priors
#   Vm ~ dnorm(0, 1 / 10^6)  # Prior for Vm
#   delV ~ dnorm(0, 1 / 10^6) # Prior for delV (change in Vm)
#   K ~ dnorm(0, 1 / 10^6)    # Prior for K
#   tau ~ dgamma(10^-3, 10^-3) # Prior for precision (inverse of variance)
#   sigma2 <- 1 / tau         # Variance for residual error
# })
# Define the model in nimble with numeric state values
code <- nimbleCode({
  for (i in 1:N) {
    y[i] ~ dnorm(mu[i], tau)  # Likelihood
    mu[i] <- ((Vm + delV * state[i]) * conc[i]) / (K + conc[i])  # Michaelis-Menten equation with numeric state interaction
  }
  
  # Priors
  Vm ~ dnorm(0, 1 / 10^6)  # Prior for Vm
  delV ~ dnorm(0, 1 / 10^6) # Prior for delV (change in Vm)
  K ~ dnorm(0, 1 / 10^6)    # Prior for K
  tau ~ dgamma(10^-3, 10^-3) # Prior for precision (inverse of variance)
  sigma2 <- 1 / tau         # Variance for residual error
})


# Convert data into nimble format
data <- list(y = y)
constants <- list(conc = conc, state = state, N = length(y))

# inits <- function() list(Vm = rnorm(1, 1, 0.1), delV = rnorm(1, 0, 0.1), K = rnorm(1, 1, 0.1), tau = rgamma(1, 1, 1))

# Correct the inits definition by making it a list (not a function)
inits <- list(Vm = rnorm(1, 1, 0.1), 
              delV = rnorm(1, 0, 0.1), 
              K = rnorm(1, 1, 0.1), 
              tau = rgamma(1, 1, 1))

# Create a nimble model
model <- nimbleModel(code, data = data, constants = constants, inits = inits)

# Compile the model
compiled_model <- compileNimble(model)

# Configure the MCMC
conf <- configureMCMC(model)
conf$printSamplers()

# Build and compile the MCMC
mcmc <- buildMCMC(conf)
compiled_mcmc <- compileNimble(mcmc, project = model)

# Run three chains, each with 15,000 iterations
set.seed(123)
samples <- runMCMC(compiled_mcmc, niter = 15000, nburnin = 5000, nchains = 3)

samplesummary <- MCMCsummary(object = samples, round = 8)
samplesummary

K_bayes <- (samplesummary$mean)[1]
Vm_bayes <- (samplesummary$mean)[2]
delV_bayes <- (samplesummary$mean)[3]
sigma2_bayes <- 1/(samplesummary$mean)[4]

bayes_pred <- (Vm_bayes + delV_bayes * state) * conc / (K_bayes + conc)

puro$bayes <- bayes_pred
```

```{r}
# Load required package
library(coda)

# Convert NIMBLE samples to mcmc.list object for coda
# NIMBLE returns a list of matrices (one per chain)
samples_mcmc <- as.mcmc.list(lapply(samples, mcmc))

# Calculate Gelman-Rubin diagnostic
gelman_diag <- gelman.diag(samples_mcmc)
print(gelman_diag)

# Extract just the point estimates (upper CI is also available)
gelman_point <- gelman_diag$psrf[, "Point est."]
print(gelman_point)

# Check if all are < 1.1 (common threshold, 1.01 is stricter)
all(gelman_point < 1.1)

# For your writeup, you can report:
max_rhat <- max(gelman_point)
cat("Maximum R-hat across all parameters:", round(max_rhat, 3))

# Calculate effective sample size
ess <- effectiveSize(samples_mcmc)
print(ess)

# TRACE PLOTS - Fix the margin error
# Option 1: Increase plot window size
dev.new(width=12, height=8)  # Opens new larger window

# Option 2: Use MCMCvis (better formatting)
library(MCMCvis)
MCMCtrace(samples, 
          params = c('Vm', 'delV', 'K', 'tau'),
          pdf = FALSE,
          Rhat = TRUE,
          n.eff = TRUE)

# Option 3: Plot individually to avoid margin issues
par(mfrow=c(2,2), mar=c(4,4,2,1))
for(param in c('K', 'Vm', 'delV', 'tau')) {
  plot(samples_mcmc[, param], main=param, density=FALSE)
}

# Option 4: Save to file instead
pdf("trace_plots.pdf", width=12, height=8)
plot(samples_mcmc)
dev.off()
```


And plot the two models together. My plot isn't the smooth one that Shuting has - she used a smoother on the plot.

```{r}
# Plot using ggplot2
ggplot(puro, aes(x = conc, y = rate, color = state, shape = state)) +
  geom_point(size = 2) +
  geom_line(data = puro, aes(x = conc, y = mod_est, color = state, linetype = "Frequentist"), linewidth = 0.7) +
  geom_line(data = puro, aes(x = conc, y = bayes, color = state, linetype = "Bayesian"), linewidth = 0.7) +
  labs(
    title = "Puromycin Data and Fitted Michaelis-Menten Curves",
    x = "Substrate concentration (ppm)",
    y = "Reaction velocity (counts/min/min)",
    color = "Treatment State",
    shape = "Treatment State",
    linetype = "Approach"
  ) +
  # scale_linetype_manual(values = c("Frequentist" = "solid", "Bayesian" = "dashed")) +  # Custom linetypes
  theme_minimal()
```


```{r}
ggplot(puro, aes(x = conc, y = rate, color = state, shape = state)) +
  geom_point(size = 2) +
  geom_line(data = puro, aes(x = conc, y = mod_est, color = state, linetype = "Frequentist"), linewidth = 0.7) +
  geom_smooth(data = puro, aes(x = conc, y = mod_est, color = state, linetype = "Frequentist"), 
              method = "loess", se = FALSE, linewidth = 0.7) +  # Smoothing applied here
  geom_smooth(data = puro, aes(x = conc, y = bayes, color = state, linetype = "Bayesian"), 
              method = "loess", se = FALSE, linewidth = 0.7) +  # Smoothing applied here
  labs(
    title = "Puromycin Data and Fitted Michaelis-Menten Curves",
    x = "Substrate concentration (ppm)",
    y = "Reaction velocity (counts/min/min)",
    color = "Treatment State",
    shape = "Treatment State",
    linetype = "Approach"
  ) +
  scale_linetype_manual(values = c("Frequentist" = "solid", "Bayesian" = "dashed")) +
  theme_minimal()
```

```{r}
# # Geweke diagnostic
# geweke <- geweke.diag(samples)
# print(geweke)
# 
# # Gelman-Rubin diagnostic
# gelman <- gelman.diag(samples)
# print(gelman)
```